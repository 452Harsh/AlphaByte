{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI6VTYK4dv8J",
        "outputId": "74683057-ffb9-487c-bc74-af9e2c7d0063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gwd2WY-ppsyh"
      },
      "outputs": [],
      "source": [
        "import whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"turbo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GatMAwLjeGp2",
        "outputId": "3480ad95-2d2d-4d83-a48d-7116016d8ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(\"aud.mp3\",language=\"Kannada\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PJ92WhreNrs",
        "outputId": "6c1d8454-c077-432b-be65-a9becfce26ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ಬೆಂಗಳೂರು ನಗರ ಪೋಲಿಸ್ ಕಮಿಶ್ನರ್ ಕಚ್ಚೆರಿಯ ಕೂಗಳತೆ ದೋರದಲ್ಲಿ ಕಳ್ಣತನ ನಡದಿದೆ. ಮಚ್ಚೋ ದೊಣ್ನೆಗಳಿಂದ ಭದರ್ತಾ ಸಿಬಂದಿಯನ ಬೆದರ್ಸಿ ಎಮ್ಬೆಸಿ ಅಪಾರ್ಟ್ಮೆಟ್ಮಿಟ್ನಲ್ಲಿ ಗಂಧದ ಮರವನ್ನ ಕಳ್ಣರು ಕದ್ದೋಯದಿದ್ದಾರೆ. ಇದೇರ್ತಿಂಗಳು ಇಪತ್ತೊಂದನೆ ತಾರಿಕ್ಕು ಗಟನೆ ನಡದಿದ್ದು ಇದು ತಡವಾಗಿ ಬೆಳಕಕಗಬಂದಿದೆ. ವಿದಾನ ಸವುದ ಠಾಣಿಯಲ್ಲಿ ಪ್ರಕರಣ ದಾಖಲಾಗಿದ್ದು ಪೋಲೀಸಿರು ತನಿಕೆ ನಡಿ� ಮಾಲಾಗಗ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure the API key for Google Generative AI\n",
        "genai.configure(api_key=\"AIzaSyCaxwrJDKfZQXLFgIHEKnD6v4yHDjwyS-A\")\n",
        "\n",
        "class GenerativeAIModel:\n",
        "    _instance = None\n",
        "\n",
        "    def __new__(cls):\n",
        "        if not cls._instance:\n",
        "            cls._instance = super().__new__(cls)\n",
        "            cls._instance.model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        return cls._instance\n",
        "\n",
        "def translate_kannada_to_english(kannada_text):\n",
        "    \"\"\"\n",
        "    Translates Kannada text to English using the Google Gemini model.\n",
        "\n",
        "    Parameters:\n",
        "        kannada_text (str): The Kannada text that needs to be translated.\n",
        "\n",
        "    Returns:\n",
        "        str: The translated text in English.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize model\n",
        "        model = GenerativeAIModel()._instance.model\n",
        "\n",
        "        # Generate translation response\n",
        "        response = model.generate_content(\n",
        "            f\"Translate this to english: {kannada_text}\"\n",
        "        )\n",
        "\n",
        "        # Extract the translation from the response\n",
        "        translated_text = response.text\n",
        "        return translated_text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", e)\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "kannada_text = result[\"text\"]\n",
        "translated_text = translate_kannada_to_english(kannada_text)\n",
        "print(\"Translation:\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "YRtl53f4efp7",
        "outputId": "328c2fbe-df06-436e-f883-f1ea0b14e5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation: There has been a theft in the vicinity of the Bengaluru City Police Commissioner's office. A gang of robbers, wielding machetes, threatened security personnel and stole sandalwood from an Embassy Apartment complex. The incident occurred on the 21st of this month, but came to light only recently. A case has been registered at the Vidhana Soudha police station and the police are investigating the matter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define paths for input and output folders\n",
        "audio_folder = \"/content/drive/MyDrive/Audio\"\n",
        "output_folder = \"/content/output\"\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Iterate through each .mp3 file in the audio folder\n",
        "for audio_file in os.listdir(audio_folder):\n",
        "    if audio_file.endswith(\".mp3\"):  # Only process .mp3 files\n",
        "        file_path = os.path.join(audio_folder, audio_file)\n",
        "        try:\n",
        "            # Transcribe the audio file\n",
        "            result = model.transcribe(file_path, language=\"Kannada\")\n",
        "            transcript = result[\"text\"]\n",
        "\n",
        "            # Save the transcript to a text file in the output folder\n",
        "            output_path = os.path.join(output_folder, f\"{os.path.splitext(audio_file)[0]}.txt\")\n",
        "            with open(output_path, \"w\") as f:\n",
        "                f.write(transcript)\n",
        "\n",
        "            print(f\"Transcript saved for {audio_file}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribing {audio_file}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A19WRUvpeq1G",
        "outputId": "aa0a5f7f-2dd1-4ffb-cf45-099e0de7659d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript saved for SandalWoodNewsStories_181.mp3\n",
            "Transcript saved for SandalWoodNewsStories_184.mp3\n",
            "Transcript saved for SandalWoodNewsStories_304.mp3\n",
            "Transcript saved for SandalWoodNewsStories_173.mp3\n",
            "Transcript saved for SandalWoodNewsStories_291.mp3\n",
            "Transcript saved for SandalWoodNewsStories_43.mp3\n",
            "Transcript saved for SandalWoodNewsStories_107.mp3\n",
            "Transcript saved for SandalWoodNewsStories_295.mp3\n",
            "Transcript saved for SandalWoodNewsStories_35.mp3\n",
            "Transcript saved for SandalWoodNewsStories_63.mp3\n",
            "Transcript saved for SandalWoodNewsStories_223.mp3\n",
            "Transcript saved for SandalWoodNewsStories_279.mp3\n",
            "Transcript saved for SandalWoodNewsStories_230.mp3\n",
            "Transcript saved for SandalWoodNewsStories_168.mp3\n",
            "Transcript saved for SandalWoodNewsStories_197.mp3\n",
            "Transcript saved for SandalWoodNewsStories_112.mp3\n",
            "Transcript saved for SandalWoodNewsStories_52.mp3\n",
            "Transcript saved for SandalWoodNewsStories_42.mp3\n",
            "Transcript saved for SandalWoodNewsStories_283.mp3\n",
            "Transcript saved for SandalWoodNewsStories_2.mp3\n",
            "Transcript saved for SandalWoodNewsStories_9.mp3\n",
            "Transcript saved for SandalWoodNewsStories_156.mp3\n",
            "Transcript saved for SandalWoodNewsStories_306.mp3\n",
            "Transcript saved for SandalWoodNewsStories_294.mp3\n",
            "Transcript saved for SandalWoodNewsStories_191.mp3\n",
            "Transcript saved for SandalWoodNewsStories_6.mp3\n",
            "Transcript saved for SandalWoodNewsStories_45.mp3\n",
            "Transcript saved for SandalWoodNewsStories_200.mp3\n",
            "Transcript saved for SandalWoodNewsStories_296.mp3\n",
            "Transcript saved for SandalWoodNewsStories_298.mp3\n",
            "Transcript saved for SandalWoodNewsStories_257.mp3\n",
            "Transcript saved for SandalWoodNewsStories_33.mp3\n",
            "Transcript saved for SandalWoodNewsStories_211.mp3\n",
            "Transcript saved for SandalWoodNewsStories_53.mp3\n",
            "Transcript saved for SandalWoodNewsStories_239.mp3\n",
            "Transcript saved for SandalWoodNewsStories_280.mp3\n",
            "Transcript saved for SandalWoodNewsStories_299.mp3\n",
            "Transcript saved for SandalWoodNewsStories_171.mp3\n",
            "Transcript saved for SandalWoodNewsStories_158.mp3\n",
            "Transcript saved for SandalWoodNewsStories_278.mp3\n",
            "Transcript saved for SandalWoodNewsStories_89.mp3\n",
            "Transcript saved for SandalWoodNewsStories_287.mp3\n",
            "Transcript saved for SandalWoodNewsStories_303.mp3\n",
            "Transcript saved for SandalWoodNewsStories_46.mp3\n",
            "Transcript saved for SandalWoodNewsStories_297.mp3\n",
            "Transcript saved for SandalWoodNewsStories_249.mp3\n",
            "Transcript saved for SandalWoodNewsStories_242.mp3\n",
            "Transcript saved for SandalWoodNewsStories_286.mp3\n",
            "Transcript saved for SandalWoodNewsStories_36.mp3\n",
            "Transcript saved for SandalWoodNewsStories_41.mp3\n",
            "Transcript saved for SandalWoodNewsStories_179.mp3\n",
            "Transcript saved for SandalWoodNewsStories_169.mp3\n",
            "Transcript saved for SandalWoodNewsStories_23.mp3\n",
            "Transcript saved for SandalWoodNewsStories_284.mp3\n",
            "Transcript saved for SandalWoodNewsStories_146.mp3\n",
            "Transcript saved for SandalWoodNewsStories_144.mp3\n",
            "Transcript saved for SandalWoodNewsStories_1.mp3\n",
            "Transcript saved for SandalWoodNewsStories_282.mp3\n",
            "Transcript saved for SandalWoodNewsStories_305.mp3\n",
            "Transcript saved for SandalWoodNewsStories_159.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define paths for input and output folders\n",
        "audio_folder = \"/content/audio\"\n",
        "output_folder = \"/content/output\"\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Iterate through each .mp3 file in the audio folder\n",
        "for audio_file in os.listdir(audio_folder):\n",
        "    if audio_file.endswith(\".mp3\"):  # Only process .mp3 files\n",
        "        file_path = os.path.join(audio_folder, audio_file)\n",
        "        try:\n",
        "            # Transcribe the audio file\n",
        "            result = model.transcribe(file_path, language=\"Kannada\")\n",
        "            transcript = result[\"text\"]\n",
        "\n",
        "            # Save the transcript to a text file in the output folder\n",
        "            output_path = os.path.join(output_folder, f\"{os.path.splitext(audio_file)[0]}.txt\")\n",
        "            with open(output_path, \"w\") as f:\n",
        "                f.write(transcript)\n",
        "\n",
        "            print(f\"Transcript saved for {audio_file}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribing {audio_file}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM7rOpjiM-9B",
        "outputId": "44aedde2-9914-4ea9-9750-e107a32b555b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript saved for SandalWoodNewsStories_172.mp3\n",
            "Transcript saved for SandalWoodNewsStories_167.mp3\n"
          ]
        }
      ]
    }
  ]
}